{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMVnTP8gvjArDzseTWOFZyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sultanmr/cifar-resnet/blob/main/train_cifar10_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Libraries"
      ],
      "metadata": {
        "id": "LKgLrCOSKZLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Libraries"
      ],
      "metadata": {
        "id": "raITKVIuKccT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXf1_96UItuE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    GlobalAveragePooling2D,\n",
        "    Input,\n",
        "    BatchNormalization,\n",
        "    Flatten,\n",
        "    Activation,\n",
        "    Dropout\n",
        ")\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping,\n",
        "    ReduceLROnPlateau,\n",
        "    TensorBoard\n",
        ")\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Limit the Dataset"
      ],
      "metadata": {
        "id": "KiSoRNn5KjRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#as per requirements from sprint\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "n = 10000\n",
        "train_images = train_images[:n]\n",
        "train_labels = train_labels[:n]"
      ],
      "metadata": {
        "id": "q_n5ijJ4KmAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocess the Data"
      ],
      "metadata": {
        "id": "PPV_QYiDKncz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting to gray scale\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "#converting to one hot encoding\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n"
      ],
      "metadata": {
        "id": "dH9MZl-qKqKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Set Up the ResNet50 Base Model"
      ],
      "metadata": {
        "id": "tZmY6he5KuZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "base_model.trainable = False  # Freeze base model\n",
        "#include_top is set to false because we don't want to include the top layer of the model"
      ],
      "metadata": {
        "id": "BplHVPRCKwrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Build the Custom Head"
      ],
      "metadata": {
        "id": "CulQEpADK14f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " model = Sequential([\n",
        "  base_model,\n",
        "  GlobalAveragePooling2D(),\n",
        "  Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "  BatchNormalization(),\n",
        "  Dropout(0.5),\n",
        "  Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "  BatchNormalization(),\n",
        "  Dropout(0.5),\n",
        "  Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "  BatchNormalization(),\n",
        "  Dropout(0.5),\n",
        "  Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "vbcktOS3K35I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Compile the Model"
      ],
      "metadata": {
        "id": "p9mn4C7NK6on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#categorical_crossentropy is being used because we do have multiple classes in one hot encoding and we want to predict the class with the highest probability\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Lud-pfKeK8w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  7. Train the Head"
      ],
      "metadata": {
        "id": "XERA_6C6K-Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_labels, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgvuhVXZLAAG",
        "outputId": "9879f8d0-f58d-40f2-aac3-c063651d0bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 536ms/step - accuracy: 0.2725 - loss: 2.1523 - val_accuracy: 0.3055 - val_loss: 6.8729\n",
            "Epoch 2/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 509ms/step - accuracy: 0.4392 - loss: 1.6621 - val_accuracy: 0.3700 - val_loss: 1.7948\n",
            "Epoch 3/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 524ms/step - accuracy: 0.5114 - loss: 1.4413 - val_accuracy: 0.4570 - val_loss: 1.6192\n",
            "Epoch 4/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 542ms/step - accuracy: 0.5768 - loss: 1.2472 - val_accuracy: 0.5820 - val_loss: 1.2667\n",
            "Epoch 5/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 531ms/step - accuracy: 0.6329 - loss: 1.0777 - val_accuracy: 0.5325 - val_loss: 1.4484\n",
            "Epoch 6/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 537ms/step - accuracy: 0.7082 - loss: 0.9202 - val_accuracy: 0.5285 - val_loss: 1.6134\n",
            "Epoch 7/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 535ms/step - accuracy: 0.7403 - loss: 0.8204 - val_accuracy: 0.5740 - val_loss: 1.2590\n",
            "Epoch 8/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 526ms/step - accuracy: 0.7739 - loss: 0.7276 - val_accuracy: 0.5915 - val_loss: 1.3256\n",
            "Epoch 9/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 522ms/step - accuracy: 0.7752 - loss: 0.7033 - val_accuracy: 0.1925 - val_loss: 6.4434\n",
            "Epoch 10/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 500ms/step - accuracy: 0.7556 - loss: 0.7639 - val_accuracy: 0.5270 - val_loss: 1.6132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import datetime\n",
        "\n",
        "# Create a log directory with a timestamp\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Create TensorBoard callback\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "BYn2k6Y2JYt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Unfreeze and Train the Whole Model"
      ],
      "metadata": {
        "id": "NE8d2amuLB33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history_fine = model.fit(train_images, train_labels, epochs=50, validation_split=0.2, callbacks=[early_stopping, tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVq05uR_LEsJ",
        "outputId": "aa6e2b14-3df5-4fb2-d2d1-0df995b38ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 677ms/step - accuracy: 0.9428 - loss: 0.2314 - val_accuracy: 0.7155 - val_loss: 0.9547\n",
            "Epoch 2/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 583ms/step - accuracy: 0.9496 - loss: 0.2025 - val_accuracy: 0.7165 - val_loss: 0.9724\n",
            "Epoch 3/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 588ms/step - accuracy: 0.9560 - loss: 0.1826 - val_accuracy: 0.7160 - val_loss: 0.9816\n",
            "Epoch 4/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 576ms/step - accuracy: 0.9565 - loss: 0.1764 - val_accuracy: 0.7200 - val_loss: 0.9871\n",
            "Epoch 5/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 570ms/step - accuracy: 0.9613 - loss: 0.1662 - val_accuracy: 0.7190 - val_loss: 0.9956\n",
            "Epoch 6/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 585ms/step - accuracy: 0.9578 - loss: 0.1664 - val_accuracy: 0.7165 - val_loss: 1.0040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Evaluate the Model"
      ],
      "metadata": {
        "id": "32PgQ1zaLH5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy:{test_acc*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4JKF2oGLJsr",
        "outputId": "4e232db3-b4ba-49cb-cf5d-44e445ad1e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 140ms/step - accuracy: 0.7254 - loss: 0.9398\n",
            "Test accuracy:72.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ctrl + S"
      ],
      "metadata": {
        "id": "G7lcgDttPdUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View Results: https://dagshub.com/sultanmr/my-first-repo.mlflow/#/experiments/2/runs/bfc550c5403b44c0a980c0629be2de58/artifacts\n",
        "#saved to load on dagshub using mlflow code is in mlflow-dagshub.py\n",
        "#saved to load on streamlit based ui code is in app.py\n",
        "model.save('resnet50_model.h5')\n",
        "\n",
        "full_history = {\n",
        "    'accuracy': history_fine.history['accuracy'] ,\n",
        "    'val_accuracy': history_fine.history['val_accuracy'],\n",
        "    'loss': history_fine.history['loss'],\n",
        "    'val_loss': history_fine.history['val_loss']\n",
        "}\n",
        "#save test data for viz of train loss and accuracy on dagshub, code is in mlflow-dagshub.py\n",
        "np.savez('history.npz', **full_history)\n",
        "\n",
        "#saved to load on dagshub using mlflow code is in mlflow-dagshub.py with confusion matrix\n",
        "np.savez('test_data.npz', images=test_images, labels=test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK0FnSKnPg3S",
        "outputId": "7f3244cb-2cf8-4140-fa27-e59e0ee94289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(full_history['accuracy'], label='Train Acc')\n",
        "plt.plot(full_history['val_accuracy'], label='Val Acc')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "    # Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(full_history['loss'], label='Train Loss')\n",
        "plt.plot(full_history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vz7aS0n6sW2j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}